@page "/"
@using System;
@using System.ComponentModel.DataAnnotations;
@using System.Collections.Concurrent;
@using Grpc.Core;
@using Grpc.Net.Client;
@using PerfRunner.V1;
@using PerfLoader.Helper;
@using Polly;
@using Polly.Registry;
@using Polly.Retry;
@using Polly.CircuitBreaker;
@inject IReadOnlyPolicyRegistry<string> PollyPolicyRegistry
@inject IConfiguration Configuration
@inject ILogger<Index> Logger

<PageTitle>Index</PageTitle>
<environment include="Development">
    <div>Environment is Development</div>
</environment>
<!-- environment exclude="Development">
    <div>Environment is NOT Development</div>
</environment>
<environment include="Staging,Development,Staging_2">
    <div>Environment is: Staging, Development or Staging_2</div>
</environment -->

<h1>Hello, world!</h1>

Welcome to Perf Loader.

<SurveyPrompt Title="How is Blazor working for you?" />
<br>

<UserMessage UserMessage_=_userMessage />
<br>

<EditForm Model="@TestRequest">
<InputSelect @bind-Value=SelectedChannels>
@foreach(var channel in _perfChannels)
{
 <option value="@channel.Target">@channel.Target</option>
}
 </InputSelect>

 <button @onclick="() => UpdateConnectionsPollyAsync()">Probe Clients</button>
<br>
    <InputText @bind-Value=TestRequest.Name></InputText>

    <InputNumber @bind-Value=TestRequest.Rate></InputNumber>


Actions: 
@foreach (var item in TestRequest.Actions)
{
    <br>
    <label>Name: @item.Name</label>
    <label>Rate: @item.Rate</label>
}
<br>
 <InputText @bind-Value=TestRequest.Actions.Last().Name></InputText>
 <InputNumber @bind-Value=TestRequest.Actions.Last().Rate></InputNumber>   
 <InputSelect @bind-Value=TestRequest.Actions.Last().LoadDistribution>
 <option value="@LoadDistribution.Even">Even</option>
 <option value="@LoadDistribution.Uneven">Uneven</option>
 </InputSelect>   
 <!-- InputDate @bind-Value=TestRequest.Actions.Last().Duration></InputDate -->
 <button @onclick="() => TestRequest.Actions.Add(TestRequest.Actions.Last())">+</button>   
 <button @onclick="() => TestRequest.Actions.RemoveAt(TestRequest.Actions.Count - 1)">-</button>
 <button @onclick="() => StartTestAsync()">Start Test</button>

 <button @onclick="() => StopAllTestsAsync()">Stop All Tests</button>
</EditForm>

Running Tests:
@foreach (var item in RunningTests)
{
 <br>
 <label>@item.Guid</label>
 <button @onclick="() => StopTest(item.Guid)">Stop</button>
}
<br>
<br>

@foreach (var item in RunningTests)
{
    <CascadingValue Value="@this">
        <MonitorTest TestRequest=item />
    </CascadingValue>
}
<br>
<button @onclick="() => CheckTests()">CheckTests</button>
 <br>
 <button @onclick="() => MonitorAllTestsAsync()">MonitorAllTests</button>

@code {

    public class PerfClientChannels_
    {
        public string[] SelectedChannels { get; set; } = new string[] { "All" };
    }

    private static ConcurrentBag<GrpcChannel> _perfChannels = new ConcurrentBag<GrpcChannel>();

    private static object _updateChannelsLock = new object();

    private static SemaphoreSlim _updateChannelsSemSlim = new SemaphoreSlim(1, 1); // 1 thr 1 con

    private ActionOption _actionOption;

    private UpdateAction _updateAction = new UpdateAction();

    private Models.UserMessage _userMessage = new Models.UserMessage();

    // will not work? [Required, MinLength(1)]
    public string[] SelectedChannels { get; set; } = new string[] { };

    private TestRequest TestRequest { get; set; }

    private CancellationToken _cancellationToken;// = new CancellationToken();

    private static IList<TestRequest> RunningTests { get; set; } = new List<TestRequest>();

    protected override async Task OnAfterRenderAsync(bool firstRender)
    {
        if (firstRender)
        {
            // on page load only - after Initialized
            Logger.LogDebug("In first render");

            // probe on every StateHasChanged
            UpdateConnectionsPollyAsync();
        }

        Logger.LogDebug("In After render");
        // base.OnAfterRender(firstRender);
    }
    protected override void OnInitialized()
    {
        NewTest();

        _cancellationToken = new CancellationToken();
        Logger.LogDebug("Running initialized!");

        // load or update Perf Clients only in beginning*
        if (_perfChannels.Count == 0)
        {
            foreach (var cli in Configuration.GetRequiredSection("PerfRunners").Get<List<string>>())
            {
                var channel = GrpcChannel.ForAddress(cli);

                Logger.LogDebug("Channel {0} was created!", channel.Target);
                _perfChannels.Add(channel);
            }
        }
    }

    private async void UpdateConnectionsPollyAsync()
    {
        // lock (_updateChannelsLock)
        await _updateChannelsSemSlim.WaitAsync();

        ConcurrentBag<GrpcChannel> chnnls = new ConcurrentBag<GrpcChannel>();

        foreach(var ch in _perfChannels)
        {
            chnnls.Add(ch);
        }

        // System.Threading.Monitor.Enter(_updateChannelsLock, ref _updateChannelsLockFlag);
        // _updateChannelsLockFlag = true;
        // foreach (var ch in _perfChannels)
        #pragma warning disable CS4014 
        Parallel.ForEachAsync(_perfChannels, (ch, cnc) =>
        {
            var perfCli = new Perf.PerfClient(ch);

            var policy = Policy.Handle<RpcException>()
            .WaitAndRetryForever(
            // retryAttempt => TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)),
            sleepDurationProvider: retryAttempt => TimeSpan.FromSeconds(3),
            onRetry: (exception, timespan, context) =>
            {
                Logger.LogInformation("Attempt {3} - Trying to connect to {0} again in {1} s.", timespan, ch.Target, context);
                // Logger.LogInformation("Context is {0}", context);

                // lets not have this
                if (_perfChannels.RemoveItem(ch))
                {
                    Logger.LogInformation("Removed - " + ch.Target);
                    InvokeAsync(StateHasChanged);
                }

                foreach (var ele in _perfChannels)
                {
                    Logger.LogInformation("Ele in " + ele.Target);
                }

                // InvokeAsync(StateHasChanged);
                /*
                if(_perfChannels.Count <= 0)
                {
                return;
                }*/
            });

            Logger.LogInformation("Pinging {0} now.", ch.Target);

            // on fail, this is running again*
            var rep = policy.Execute(() =>
            perfCli.Ping(new PingRequest())
            );

            // InvokeAsync(StateHasChanged);

            if (!_perfChannels.Contains(ch))
            {
                Logger.LogInformation("Adding - " + ch.Target);
                _perfChannels.Add(ch);
                InvokeAsync(StateHasChanged);
            }

            return default;
        });
        // , cncl.Token, task);

        Logger.LogDebug("Finished Parallel loop");

        _updateChannelsSemSlim.Release();
    }


    public class UpdateAction
    {
        public ActionOption ActionOption { get; set; }

        public string TestGuid { get; set; }
    }

    public async Task HandleUpdateAction(string actionGuid, ActionOptionUpdated actionOptionUpdated, string testGuid,
    EventArgs e)
    // private async Task HandleUpdateAction(EditContext editContext)
    {
        // var testGuid = "test";

        try
        {
            // Logger.LogInformation("Updating test " + _updateAction.TestGuid);
            if (e is ChangeEventArgs ce)
            {
                Logger.LogInformation("Updating action " + actionGuid);

                // var action = (UpdateAction)editContext.Model;
                var updateAction = new UpdateActionRequest()
                    {
                        // Guid = action.TestGuid,
                        TestGuid = testGuid,
                        // TestGuid = _updateAction.TestGuid,
                        ActionGuid = actionGuid,
                        ActionOptionUpdate = actionOptionUpdated,
                        UpdateValue = (string)ce.Value.ToString()
                    };

                void UpdateAction(GrpcChannel? cli)
                {

                    var perfCli = new Perf.PerfClient(cli);
                    var rep = perfCli.UpdateActionAsync(updateAction);
                }

                // not wait for task to complete
                foreach (var cli in _perfChannels)
                {
                    // if no selection, run in all
                    if (SelectedChannels.Length > 0)
                    {
                        Parallel.ForEach(SelectedChannels, (item) =>
                        {

                            // check only if any sel made
                            if (item.Contains(cli.Target))
                            {
                                // if(cli.)
                                UpdateAction(cli);
                            }
                        });
                    }
                    else
                    {
                        UpdateAction(cli);
                    }
                }
            }
        }
        catch (Exception ex)
        {
            Logger.LogError("Update action failed " + ex.Message);
        }
    }

    private void NewTest()
    {

        TestRequest = new TestRequest()
            {
                Name = "Test Name",
                Guid = Guid.NewGuid().ToString(),
                // Duration = Google.Protobuf.WellKnownTypes.Duration.FromTimeSpan(TimeSpan.FromSeconds(10))
                Rate = 3,
            };

        _actionOption = new ActionOption()
            {
                Name = "Login",
                Rate = 6,
                // Duration = Google.Protobuf.WellKnownTypes.Duration.FromTimeSpan(TimeSpan.FromSeconds(10)),
                // Duration = Google.Protobuf.WellKnownTypes.Duration.FromTimeSpan(TimeSpan.MaxValue),
                Guid = Guid.NewGuid().ToString(),
            };

        // Logger.LogInformation("Action " + _actionOption.Guid);

        TestRequest.Actions.Add(_actionOption);
        _updateAction.ActionOption ??= _actionOption;

        _actionOption = new ActionOption()
            {
                Name = "PlayBowling",
                Rate = 3,
                // Duration = Google.Protobuf.WellKnownTypes.Duration.FromTimeSpan(TimeSpan.FromSeconds(16)),
                // Duration = Google.Protobuf.WellKnownTypes.Duration.FromTimeSpan(TimeSpan.MaxValue),
                Guid = Guid.NewGuid().ToString()
            };

        // Logger.LogInformation("Action " + _actionOption.Guid);

        TestRequest.Actions.Add(_actionOption);

        _updateAction.ActionOption ??= _actionOption;
        _updateAction.TestGuid ??= TestRequest.Guid;

        /*
        actionOption = new ActionOption()
        {
        Name = "LoginGrpc",
        Rate = 3,
        Guid = Guid.NewGuid().ToString()
        };
        TestRequest.Actions.Add(actionOption);*/
    }

    private bool AreClientsAvailable()
    {
        if (_perfChannels.Count <= 0)
        {
            _userMessage.WarningMessage = "None of the clients are running!";
            Logger.LogError(_userMessage.WarningMessage);
            return false;
        }

        return true;
    }

    private async void StartTestAsync()
    {
        if(!AreClientsAvailable())
        {
            return;
        }

        _userMessage.InfoMessage = "Starting test " + TestRequest.Guid;
        Logger.LogInformation(_userMessage.InfoMessage);

        // not wait for task to complete
        // var rep = PerfClient.RunTestAsync(TestRequest);
        foreach (var cli in _perfChannels)
        {
            void RunTest()
            {
                TestRequest.Clients.Add(cli.Target);
                var perfCli = new Perf.PerfClient(cli);
                var rep = perfCli.RunTestAsync(TestRequest);
            }

            // if no selection, run in all
            if (SelectedChannels.Length > 0)
            {
                Parallel.ForEach(SelectedChannels, (item) =>
                {
                    // check only if any sel made
                    if (item.Contains(cli.Target))
                    {
                        RunTest();
                    }
                });
            }
            else
            {
                RunTest();
            }
        }

        RunningTests.Add(TestRequest);

        NewTest();
    }

    public void StopTest(string guid)
    {
        if (!AreClientsAvailable())
        {
            return;
        }

        _userMessage.InfoMessage = "Stopping test " + guid;
        Logger.LogInformation(_userMessage.InfoMessage);

        // var rep = PerfClient.StopTestAsync(new StopTestRequest { Guid = guid });
        foreach (var cli in _perfChannels)
        {
            void StopTest()
            {
                var perfCli = new Perf.PerfClient(cli);
                var rep = perfCli.StopTestAsync(new StopTestRequest { Guid = guid });
            }

            // if no selection, run in all
            if (SelectedChannels.Length > 0)
            {
                Parallel.ForEach(SelectedChannels, (item) =>
                {

                    // check only if any sel made
                    if (item.Contains(cli.Target))
                    {
                        StopTest();
                    }
                });
            }
            else
            {
                StopTest();
            }
        }

        // StateHasChanged();
        // RunningTests.Remove(test => test.Guid.Equals(guid));
        RunningTests.Remove(RunningTests.Where(test => test.Guid.Equals(guid)).First());

        StateHasChanged();

        // CheckTests();
    }

    private async void StopAllTestsAsync()
    {
        if(!AreClientsAvailable())
        {
            return;
        }

        foreach (var cli in _perfChannels)
        {
            foreach (var item_ in RunningTests)
            {
                Logger.LogInformation("Stopping test " + item_.Guid);

                void StopAllTests()
                {
                    var perfCli = new Perf.PerfClient(cli);
                    var rep = perfCli.StopTestAsync(new StopTestRequest { Guid = item_.Guid });
                }

                // not wait for task to complete
                // var rep = PerfClient.StopTestAsync(new StopTestRequest { Guid = item.Guid });
                // RunningTests.Remove(item);
                // if no selection, run in all
                if (SelectedChannels.Length > 0)
                {
                    Parallel.ForEach(SelectedChannels, (item) =>
                    {
                        // check only if any sel made
                        if (item.Contains(cli.Target))
                        {
                            StopAllTests();
                        }
                    });
                }
                else
                {
                    StopAllTests();
                }
            }
        }

        RunningTests.Clear();
    }

    private void CheckTests()
    {
        if(!AreClientsAvailable())
        {
            return;
        }

        RunningTests.Clear();

        foreach (var cli in _perfChannels)
        {
            // if no selection, run in all
            if (SelectedChannels.Length > 0)
            {

                Parallel.ForEach(SelectedChannels, (item) =>
                {
                    // check only if any sel made
                    if (item.Contains(cli.Target))
                    {
                        RunningTests_();
                    }
                });
            }
            else
            {
                RunningTests_();
            }

            void RunningTests_()
            {
                try
                {
                    // var res = PerfClient.RunningTests(new RunningTestsRequest());
                    var perfCli = new Perf.PerfClient(cli);
                    var res = perfCli.RunningTests(new RunningTestsRequest());

                    foreach (var test in res.Tests)
                    {
                        if (RunningTests.Count > 0)
                        {
                            if (!RunningTests.Select(item => item.Guid.Equals(test.Guid)).First())
                            {
                                RunningTests.Add(test);
                            }
                        }
                        else
                        {
                            RunningTests.Add(test);
                        }
                    }
                }
                catch (Grpc.Core.RpcException exc)
                {
                    Logger.LogError($"Unable to fetch tests - {exc.Message}");

                    // if unavail remove them? causing exc
                    // _perfClients.Remove(cli);
                }
            }
        }
    }

    private async void MonitorAllTestsAsync()
    {
        if(!AreClientsAvailable())
        {
            return;
        }

        var cancelToken = new CancellationTokenSource();

        Parallel.ForEach(_perfChannels, async cli => EachCli(cli));

        async void EachCli(GrpcChannel cli)
        {
            Parallel.ForEach(RunningTests, async item => MonitorParallel(item));

            async void MonitorParallel(TestRequest item)
            {
                Logger.LogInformation("Monitoring test " + item.Guid);

                async void MonitorTests_()
                {

                    try
                    {
                        // not wait for task to complete
                        var perfCli = new Perf.PerfClient(cli);
                        using var resp = perfCli.MonitorTest(new MonitorTestRequest { Guid = item.Guid }, cancellationToken: cancelToken.Token);

                        await foreach (var item1 in resp.ResponseStream.ReadAllAsync(cancelToken.Token))
                        {
                            var resp_ = item1;
                            Logger.LogInformation($"Test is {item1.Name} .");
                            // state?.Invoke();
                            StateHasChanged();
                            // cancelToken.Cancel();
                        }

                    }
                    catch (InvalidOperationException ex)
                    {
                        Logger.LogDebug($"Monitor failed for test {item.Name} with {ex.Message}.");
                        // RunningTests.Remove(item);
                        item = null;
                    }
                    catch (System.Exception ex)
                    {
                        Logger.LogDebug($"Monitor failed for test {item.Name} with {ex.Message}.");
                        // RunningTests.Remove(item);
                        item = null;
                        // throw;
                    }
                    finally
                    {
                        // RunningTests.Remove(item);
                    }
                }

                // if no selection, run in all
                if (SelectedChannels.Length > 0)
                {

                    Parallel.ForEach(SelectedChannels, (item0) =>
                    {
                        // check only if any sel made
                        if (item0.Contains(cli.Target))
                        {
                            MonitorTests_();
                        }
                    });
                }
                else
                {
                    MonitorTests_();
                }

            }
        }

        // RunningTests.Clear();
        foreach (var ele in RunningTests)
        {
            if (ele is null)
            {
                RunningTests.Remove(ele);
            }
        }

        StateHasChanged();
    }
}